{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rising-uzbekistan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label.value</th>\n",
       "      <th>abstract.value</th>\n",
       "      <th>words_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Implantable loop recorder</td>\n",
       "      <td>An implantable loop recorder (ILR), also known...</td>\n",
       "      <td>Implants_(medicine)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Health Canada</td>\n",
       "      <td>Health Canada (HC; French: Santé Canada, SC) i...</td>\n",
       "      <td>Regulation_of_medical_devices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Visual prosthesis</td>\n",
       "      <td>A visual prosthesis, often referred to as a bi...</td>\n",
       "      <td>Implants_(medicine),Neuroprosthetics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Medical Devices Directive</td>\n",
       "      <td>The Medical Device Directive (Council Directiv...</td>\n",
       "      <td>Regulation_of_medical_devices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nasal spray</td>\n",
       "      <td>Nasal sprays are used to deliver medications l...</td>\n",
       "      <td>Drug_delivery_devices,Nasal_sprays</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 label.value  \\\n",
       "0  Implantable loop recorder   \n",
       "1              Health Canada   \n",
       "2          Visual prosthesis   \n",
       "3  Medical Devices Directive   \n",
       "4                Nasal spray   \n",
       "\n",
       "                                      abstract.value  \\\n",
       "0  An implantable loop recorder (ILR), also known...   \n",
       "1  Health Canada (HC; French: Santé Canada, SC) i...   \n",
       "2  A visual prosthesis, often referred to as a bi...   \n",
       "3  The Medical Device Directive (Council Directiv...   \n",
       "4  Nasal sprays are used to deliver medications l...   \n",
       "\n",
       "                           words_string  \n",
       "0                   Implants_(medicine)  \n",
       "1         Regulation_of_medical_devices  \n",
       "2  Implants_(medicine),Neuroprosthetics  \n",
       "3         Regulation_of_medical_devices  \n",
       "4    Drug_delivery_devices,Nasal_sprays  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "df = pd.read_csv('medical_devices_cleanData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "controlled-steering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(427, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df['abstract.value'].values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "features = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = pd.DataFrame(data = features.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "final_df = tf_idf\n",
    "\n",
    "print(\"{} rows\".format(final_df.shape[0]))\n",
    "final_df.T.nlargest(5, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-latitude",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# first 5 words with highest weight on document 0:\n",
    "final_df.T.nlargest(5, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-bangkok",
   "metadata": {},
   "source": [
    "K-Means\n",
    "Function that runs the K-Means algorithm max_k times and returns a dictionary of each k result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-construction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means\n",
    "from sklearn import cluster\n",
    "import numpy as np\n",
    "# Visualization and Analysis\n",
    "import matplotlib.pyplot  as plt\n",
    "import matplotlib.cm      as cm\n",
    "import seaborn            as sns\n",
    "from sklearn.metrics                  import silhouette_samples, silhouette_score\n",
    "from wordcloud                        import WordCloud\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_KMeans(max_k, data):\n",
    "    max_k += 1\n",
    "    kmeans_results = dict()\n",
    "    for k in range(2 , max_k):\n",
    "        kmeans = cluster.KMeans(n_clusters = k\n",
    "                               , init = 'k-means++'\n",
    "                               , n_init = 10\n",
    "                               , tol = 0.0001\n",
    "                               , n_jobs = -1\n",
    "                               , random_state = 1\n",
    "                               , algorithm = 'full')\n",
    "\n",
    "        kmeans_results.update( {k : kmeans.fit(data)} )\n",
    "        \n",
    "    return kmeans_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printAvg(avg_dict):\n",
    "    for avg in sorted(avg_dict.keys(), reverse=True):\n",
    "        print(\"Avg: {}\\tK:{}\".format(avg.round(4), avg_dict[avg]))\n",
    "        \n",
    "def plotSilhouette(df, n_clusters, kmeans_labels, silhouette_avg):\n",
    "    fig, ax1 = plt.subplots(1)\n",
    "    fig.set_size_inches(8, 6)\n",
    "    ax1.set_xlim([-0.2, 1])\n",
    "    ax1.set_ylim([0, len(df) + (n_clusters + 1) * 10])\n",
    "    \n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\") # The vertical line for average silhouette score of all the values\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.2, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    plt.title((\"Silhouette analysis for K = %d\" % n_clusters), fontsize=10, fontweight='bold')\n",
    "    \n",
    "    y_lower = 10\n",
    "    sample_silhouette_values = silhouette_samples(df, kmeans_labels) # Compute the silhouette scores for each sample\n",
    "    for i in range(n_clusters):\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[kmeans_labels == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values, facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i)) # Label the silhouette plots with their cluster numbers at the middle\n",
    "        y_lower = y_upper + 10  # Compute the new y_lower for next plot. 10 for the 0 samples\n",
    "    plt.show()\n",
    "    \n",
    "        \n",
    "def silhouette(kmeans_dict, df, plot=False):\n",
    "    df = df.to_numpy()\n",
    "    avg_dict = dict()\n",
    "    for n_clusters, kmeans in kmeans_dict.items():      \n",
    "        kmeans_labels = kmeans.predict(df)\n",
    "        silhouette_avg = silhouette_score(df, kmeans_labels) # Average Score for all Samples\n",
    "        avg_dict.update( {silhouette_avg : n_clusters} )\n",
    "    \n",
    "        if(plot): plotSilhouette(df, n_clusters, kmeans_labels, silhouette_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-enforcement",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3,50):\n",
    "    labels=cluster.KMeans(n_clusters=i,init=\"k-means++\",random_state=200).fit(final_df).labels_\n",
    "    print (\"Silhouette score for k(clusters) = \"+str(i)+\" is \"\n",
    "           +str(metrics.silhouette_score(final_df,labels,metric=\"euclidean\",sample_size=1000,random_state=200)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-attitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Kmeans\n",
    "k = 7\n",
    "kmeans_results = run_KMeans(k, final_df)\n",
    "\n",
    "# Plotting Silhouette Analysis\n",
    "silhouette(kmeans_results, final_df, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_features_cluster(tf_idf_array, prediction, n_feats):\n",
    "    labels = np.unique(prediction)\n",
    "    dfs = []\n",
    "    for label in labels:\n",
    "        id_temp = np.where(prediction==label) # indices for each cluster\n",
    "        x_means = np.mean(tf_idf_array[id_temp], axis = 0) # returns average score across cluster\n",
    "        sorted_means = np.argsort(x_means)[::-1][:n_feats] # indices with top 20 scores\n",
    "        features = vectorizer.get_feature_names()\n",
    "        best_features = [(features[i], x_means[i]) for i in sorted_means]\n",
    "        df = pd.DataFrame(best_features, columns = ['features', 'score'])\n",
    "        dfs.append(df)\n",
    "    return dfs\n",
    "\n",
    "def plotWords(dfs, n_feats):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    for i in range(0, len(dfs)):\n",
    "        plt.title((\"Most Common Words in Cluster {}\".format(i)), fontsize=10, fontweight='bold')\n",
    "        sns.barplot(x = 'score' , y = 'features', orient = 'h' , data = dfs[i][:n_feats])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = 5\n",
    "kmeans = kmeans_results.get(best_result)\n",
    "\n",
    "final_df_array = final_df.to_numpy()\n",
    "prediction = kmeans.predict(final_df)\n",
    "n_feats = 20\n",
    "dfs = get_top_features_cluster(final_df_array, prediction, n_feats)\n",
    "plotWords(dfs, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-error",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster'] = kmeans.labels_\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "random_state = 0 \n",
    "pca = PCA(n_components=2, random_state=random_state)\n",
    "reduced_features = pca.fit_transform(features.toarray())\n",
    "\n",
    "# reduce the cluster centers to 2D\n",
    "reduced_cluster_centers = pca.transform(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(reduced_features[:,0], reduced_features[:,1], c=kmeans.predict(features))\n",
    "plt.scatter(reduced_cluster_centers[:, 0], reduced_cluster_centers[:,1], marker='x', s=150, c='b')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
